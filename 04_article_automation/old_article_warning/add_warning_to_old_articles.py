#!/usr/bin/env python3
"""
1å¹´ä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„è¨˜äº‹ã«æ³¨æ„æ›¸ãã‚’ä¸€æ‹¬è¿½åŠ ã™ã‚‹ãƒ¡ã‚¤ãƒ³ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
"""

import requests
import os
import json
import time
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
TEAM_NAME = os.getenv("DOCBASE_TEAM", "go")
ACCESS_TOKEN = os.getenv("DOCBASE_ACCESS_TOKEN")

if not ACCESS_TOKEN:
    print("ã‚¨ãƒ©ãƒ¼: DOCBASE_ACCESS_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
    exit(1)

# æ³¨æ„æ›¸ãã®ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆ
WARNING_TEXT = """âš ï¸ **ã“ã®è¨˜äº‹ã¯1å¹´ä»¥ä¸Šå‰ã«æ›¸ã‹ã‚ŒãŸã‚‚ã®ã§ã™ã€‚æƒ…å ±ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚**

---

"""

def get_all_articles_paginated(max_pages=50):
    """
    å…¨è¨˜äº‹ã‚’æ®µéšçš„ã«å–å¾—ï¼ˆå¤§é‡è¨˜äº‹å¯¾å¿œï¼‰
    """
    url = f"https://api.docbase.io/teams/{TEAM_NAME}/posts"
    headers = {
        "X-DocBaseToken": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    all_articles = []
    page = 1
    per_page = 50  # åŠ¹ç‡åŒ–ã®ãŸã‚50ä»¶ãšã¤
    
    print(f"ğŸ“š å…¨è¨˜äº‹ã‚’å–å¾—ä¸­ï¼ˆæœ€å¤§ {max_pages * per_page} ä»¶ï¼‰...")
    
    while page <= max_pages:
        params = {
            "page": page,
            "per_page": per_page
        }
        
        try:
            print(f"   ãƒšãƒ¼ã‚¸ {page} å–å¾—ä¸­...", end="")
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            articles = data.get("posts", [])
            
            if not articles:
                print(" è¨˜äº‹ãªã—ï¼ˆçµ‚äº†ï¼‰")
                break
                
            all_articles.extend(articles)
            print(f" {len(articles)} ä»¶å–å¾—ï¼ˆç´¯è¨ˆ: {len(all_articles)} ä»¶ï¼‰")
            
            page += 1
            time.sleep(0.5)  # APIåˆ¶é™å¯¾ç­–
            
        except requests.exceptions.RequestException as e:
            print(f" âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            break
    
    print(f"âœ… åˆè¨ˆ {len(all_articles)} ä»¶ã®è¨˜äº‹ã‚’å–å¾—å®Œäº†")
    return all_articles

def find_articles_needing_warning(articles, months_threshold=12):
    """
    æ³¨æ„æ›¸ããŒå¿…è¦ãªè¨˜äº‹ã‚’ç‰¹å®š
    """
    threshold_date = datetime.now() - timedelta(days=months_threshold * 30)
    target_articles = []
    
    print(f"\nğŸ” {months_threshold}ãƒ¶æœˆä»¥ä¸Šæ›´æ–°ã•ã‚Œã¦ã„ãªã„è¨˜äº‹ã‚’æ¤œç´¢...")
    print(f"åŸºæº–æ—¥: {threshold_date.strftime('%Y-%m-%d')}")
    
    for article in articles:
        try:
            updated_at_str = article.get("updated_at") or article.get("created_at")
            if not updated_at_str:
                continue
            
            # æ—¥æ™‚ã‚’ãƒ‘ãƒ¼ã‚¹
            updated_at = datetime.fromisoformat(updated_at_str.replace('Z', '+00:00'))
            updated_at_naive = updated_at.replace(tzinfo=None)
            
            if updated_at_naive < threshold_date:
                article_info = {
                    "id": article.get("id"),
                    "title": article.get("title", "ç„¡é¡Œ"),
                    "updated_at": updated_at_str,
                    "url": article.get("url"),
                    "scope": article.get("scope", "unknown")
                }
                target_articles.append(article_info)
                
        except Exception as e:
            continue
    
    print(f"ğŸ“Š å¯¾è±¡è¨˜äº‹: {len(target_articles)} ä»¶")
    return target_articles

def get_article_content(article_id):
    """
    è¨˜äº‹ã®è©³ç´°å†…å®¹ã‚’å–å¾—
    """
    url = f"https://api.docbase.io/teams/{TEAM_NAME}/posts/{article_id}"
    headers = {
        "X-DocBaseToken": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¨˜äº‹å–å¾—ã‚¨ãƒ©ãƒ¼ (ID: {article_id}): {e}")
        return None

def has_warning_already(body):
    """
    æ—¢ã«æ³¨æ„æ›¸ããŒå­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    """
    warning_indicators = [
        "ã“ã®è¨˜äº‹ã¯1å¹´ä»¥ä¸Šå‰ã«æ›¸ã‹ã‚ŒãŸã‚‚ã®ã§ã™",
        "æƒ…å ±ãŒå¤ã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™",
        "âš ï¸ **ã“ã®è¨˜äº‹ã¯1å¹´ä»¥ä¸Šå‰"
    ]
    
    for indicator in warning_indicators:
        if indicator in body:
            return True
    return False

def add_warning_to_article(article_id, dry_run=True):
    """
    è¨˜äº‹ã«æ³¨æ„æ›¸ãã‚’è¿½åŠ 
    """
    # è¨˜äº‹å†…å®¹ã‚’å–å¾—
    article = get_article_content(article_id)
    if not article:
        return False
    
    title = article.get("title", "ç„¡é¡Œ")
    body = article.get("body", "")
    
    # æ—¢ã«æ³¨æ„æ›¸ããŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
    if has_warning_already(body):
        print(f"   â­ï¸  æ—¢ã«æ³¨æ„æ›¸ãæ¸ˆã¿")
        return True
    
    # æ–°ã—ã„æœ¬æ–‡ã‚’ä½œæˆ
    new_body = WARNING_TEXT + body
    
    if dry_run:
        print(f"   âœï¸  æ³¨æ„æ›¸ãè¿½åŠ äºˆå®šï¼ˆdry_runï¼‰")
        return True
    
    # å®Ÿéš›ã«è¨˜äº‹ã‚’æ›´æ–°
    url = f"https://api.docbase.io/teams/{TEAM_NAME}/posts/{article_id}"
    headers = {
        "X-DocBaseToken": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    update_data = {"body": new_body}
    
    try:
        response = requests.patch(url, headers=headers, json=update_data)
        response.raise_for_status()
        print(f"   âœ… æ³¨æ„æ›¸ãè¿½åŠ å®Œäº†")
        return True
        
    except requests.exceptions.RequestException as e:
        print(f"   âŒ æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        return False

def process_all_old_articles(dry_run=True, max_articles=None):
    """
    å¤ã„è¨˜äº‹ã‚’ä¸€æ‹¬å‡¦ç†ã™ã‚‹ãƒ¡ã‚¤ãƒ³é–¢æ•°
    """
    print("ğŸš€ å¤ã„è¨˜äº‹ã¸ã®æ³¨æ„æ›¸ãä¸€æ‹¬è¿½åŠ ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 60)
    
    if dry_run:
        print("ğŸ” DRY RUN ãƒ¢ãƒ¼ãƒ‰: å®Ÿéš›ã®æ›´æ–°ã¯è¡Œã„ã¾ã›ã‚“")
    else:
        print("âš ï¸  å®Ÿéš›ã«è¨˜äº‹ã‚’æ›´æ–°ã—ã¾ã™")
        input("ç¶šè¡Œã™ã‚‹ã«ã¯ Enter ã‚’æŠ¼ã—ã¦ãã ã•ã„...")
    
    # å…¨è¨˜äº‹ã‚’å–å¾—
    all_articles = get_all_articles_paginated(max_pages=50)
    
    if not all_articles:
        print("âŒ è¨˜äº‹ãŒå–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
        return
    
    # å¤ã„è¨˜äº‹ã‚’ç‰¹å®š
    old_articles = find_articles_needing_warning(all_articles)
    
    if not old_articles:
        print("ğŸ‰ 1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸï¼")
        print("   ã™ã¹ã¦ã®è¨˜äº‹ãŒæœ€æ–°ã®çŠ¶æ…‹ã§ã™ã€‚")
        return
    
    # å‡¦ç†ä»¶æ•°ã‚’åˆ¶é™ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
    if max_articles:
        old_articles = old_articles[:max_articles]
        print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆç”¨ã«æœ€åˆã® {max_articles} ä»¶ã®ã¿å‡¦ç†ã—ã¾ã™")
    
    print(f"\nğŸ”§ {len(old_articles)} ä»¶ã®è¨˜äº‹ã‚’å‡¦ç†é–‹å§‹")
    print("-" * 60)
    
    success_count = 0
    skip_count = 0
    error_count = 0
    
    for i, article in enumerate(old_articles, 1):
        article_id = article.get("id")
        title = article.get("title", "ç„¡é¡Œ")[:50]
        
        print(f"[{i:3d}/{len(old_articles)}] ID:{article_id} - {title}...")
        
        if add_warning_to_article(article_id, dry_run=dry_run):
            success_count += 1
        else:
            error_count += 1
        
        # APIåˆ¶é™å¯¾ç­–
        if not dry_run:
            time.sleep(2)  # 2ç§’å¾…æ©Ÿ
    
    # çµæœã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("ğŸ“Š å‡¦ç†å®Œäº†ã‚µãƒãƒªãƒ¼:")
    print(f"   å‡¦ç†å¯¾è±¡: {len(old_articles)} ä»¶")
    print(f"   æˆåŠŸ: {success_count} ä»¶")
    print(f"   ã‚¨ãƒ©ãƒ¼: {error_count} ä»¶")
    
    if dry_run:
        print(f"\nğŸ¯ å®Ÿéš›ã«æ›´æ–°ã™ã‚‹å ´åˆ:")
        print(f"   python add_warning_to_old_articles.py --execute")

def main():
    import sys
    
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®å‡¦ç†
    dry_run = True
    max_articles = None
    
    if len(sys.argv) > 1:
        if sys.argv[1] == "--execute":
            dry_run = False
        elif sys.argv[1] == "--test":
            max_articles = 5  # ãƒ†ã‚¹ãƒˆç”¨ã«5ä»¶ã®ã¿
    
    print("ğŸ’¡ ä½¿ç”¨æ–¹æ³•:")
    print("   python add_warning_to_old_articles.py           # ç¢ºèªã®ã¿ï¼ˆæ¨å¥¨ï¼‰")
    print("   python add_warning_to_old_articles.py --test    # 5ä»¶ã®ã¿ãƒ†ã‚¹ãƒˆ")
    print("   python add_warning_to_old_articles.py --execute # å®Ÿéš›ã«æ›´æ–°")
    print()
    
    # ãƒ¡ã‚¤ãƒ³å‡¦ç†ã‚’å®Ÿè¡Œ
    process_all_old_articles(dry_run=dry_run, max_articles=max_articles)

if __name__ == "__main__":
    main()