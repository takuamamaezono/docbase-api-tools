#!/usr/bin/env python3
"""
æ‹¡å¼µæ¤œç´¢ï¼šã‚ˆã‚Šå¤šãã®ãƒšãƒ¼ã‚¸ã¨ç•°ãªã‚‹æ¤œç´¢æ¡ä»¶ã§å¤ã„è¨˜äº‹ã‚’æ¢ã™
"""

import requests
import os
import json
from datetime import datetime, timedelta
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°èª­ã¿è¾¼ã¿
load_dotenv()

# è¨­å®š
TEAM_NAME = os.getenv("DOCBASE_TEAM", "go")
ACCESS_TOKEN = os.getenv("DOCBASE_ACCESS_TOKEN")

def search_wide_range():
    """
    å¹…åºƒã„ãƒšãƒ¼ã‚¸ç¯„å›²ã§æ¤œç´¢
    """
    url = f"https://api.docbase.io/teams/{TEAM_NAME}/posts"
    headers = {
        "X-DocBaseToken": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    print("ğŸ” æ‹¡å¼µç¯„å›²æ¤œç´¢é–‹å§‹")
    print("=" * 40)
    
    # ã‚ˆã‚Šåºƒã„ç¯„å›²ã®ãƒšãƒ¼ã‚¸ã‚’æ¤œç´¢
    search_pages = list(range(100, 50, -5))  # 100, 95, 90, ..., 55
    search_pages.extend(list(range(200, 150, -10)))  # 200, 190, 180, ..., 160
    
    all_old_articles = []
    total_articles_checked = 0
    
    for page in search_pages:
        params = {
            "page": page,
            "per_page": 50
        }
        
        try:
            print(f"ğŸ“– ãƒšãƒ¼ã‚¸ {page} æ¤œç´¢ä¸­...", end="")
            response = requests.get(url, headers=headers, params=params)
            response.raise_for_status()
            
            data = response.json()
            articles = data.get("posts", [])
            
            if not articles:
                print(" è¨˜äº‹ãªã—")
                continue
            
            print(f" {len(articles)} ä»¶å–å¾—")
            total_articles_checked += len(articles)
            
            # 6ãƒ¶æœˆä»¥ä¸Šå¤ã„è¨˜äº‹ã‚‚å«ã‚ã¦æ¤œç´¢ï¼ˆæ¡ä»¶ã‚’ç·©å’Œï¼‰
            threshold_6months = datetime.now() - timedelta(days=183)  # 6ãƒ¶æœˆ
            threshold_1year = datetime.now() - timedelta(days=365)    # 1å¹´
            
            old_6months = []
            old_1year = []
            
            for article in articles:
                try:
                    updated_at_str = article.get("updated_at") or article.get("created_at")
                    if not updated_at_str:
                        continue
                    
                    updated_at = datetime.fromisoformat(updated_at_str.replace('Z', '+00:00'))
                    updated_at_naive = updated_at.replace(tzinfo=None)
                    
                    days_ago = (datetime.now() - updated_at_naive).days
                    
                    article_info = {
                        "id": article.get("id"),
                        "title": article.get("title", "ç„¡é¡Œ"),
                        "updated_at": updated_at_str,
                        "days_ago": days_ago,
                        "url": article.get("url"),
                        "scope": article.get("scope", "unknown")
                    }
                    
                    if updated_at_naive < threshold_1year:
                        old_1year.append(article_info)
                        all_old_articles.append(article_info)
                        
                        years = days_ago // 365
                        months = (days_ago % 365) // 30
                        print(f"   ğŸ”´ 1å¹´ä»¥ä¸Šå‰: ID:{article_info['id']} ({years}å¹´{months}ãƒ¶æœˆå‰)")
                        print(f"      {article_info['title'][:50]}...")
                        
                    elif updated_at_naive < threshold_6months:
                        old_6months.append(article_info)
                        months = days_ago // 30
                        print(f"   ğŸŸ¡ 6ãƒ¶æœˆä»¥ä¸Šå‰: ID:{article_info['id']} ({months}ãƒ¶æœˆå‰)")
                        print(f"      {article_info['title'][:40]}...")
                        
                except Exception as e:
                    continue
            
            if old_1year:
                print(f"   âœ… 1å¹´ä»¥ä¸Šå‰ã®è¨˜äº‹: {len(old_1year)} ä»¶")
            if old_6months:
                print(f"   âš ï¸  6ãƒ¶æœˆä»¥ä¸Šå‰ã®è¨˜äº‹: {len(old_6months)} ä»¶")
            
            # 1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹ãŒè¦‹ã¤ã‹ã£ãŸã‚‰ä¸€å®šæ•°ã§åœæ­¢
            if len(all_old_articles) >= 20:
                print(f"\nğŸ¯ {len(all_old_articles)} ä»¶ã®1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹ã‚’ç™ºè¦‹ã—ãŸãŸã‚æ¤œç´¢çµ‚äº†")
                break
                
        except requests.exceptions.RequestException as e:
            print(f" âŒ ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    print(f"\nğŸ“Š æ¤œç´¢çµæœ:")
    print(f"   ãƒã‚§ãƒƒã‚¯ã—ãŸè¨˜äº‹æ•°: {total_articles_checked} ä»¶")
    print(f"   1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹: {len(all_old_articles)} ä»¶")
    
    return all_old_articles

def check_specific_old_articles():
    """
    ç‰¹å®šã®å¤ãã†ãªè¨˜äº‹IDã‚’ç›´æ¥ãƒã‚§ãƒƒã‚¯
    """
    print(f"\nğŸ” ç‰¹å®šè¨˜äº‹ã®å¹´æ•°ãƒã‚§ãƒƒã‚¯")
    print("-" * 30)
    
    # IDãŒå°ã•ã„è¨˜äº‹ï¼ˆå¤ã„å¯èƒ½æ€§ãŒé«˜ã„ï¼‰ã‚’ãƒã‚§ãƒƒã‚¯
    test_ids = [100000, 200000, 300000, 500000, 700000, 800000, 1000000]
    
    url_base = f"https://api.docbase.io/teams/{TEAM_NAME}/posts"
    headers = {
        "X-DocBaseToken": ACCESS_TOKEN,
        "Content-Type": "application/json"
    }
    
    found_old = []
    
    for article_id in test_ids:
        try:
            url = f"{url_base}/{article_id}"
            response = requests.get(url, headers=headers)
            
            if response.status_code == 404:
                print(f"ID:{article_id} - è¨˜äº‹ãªã—")
                continue
                
            response.raise_for_status()
            article = response.json()
            
            updated_at_str = article.get("updated_at") or article.get("created_at")
            if not updated_at_str:
                continue
            
            updated_at = datetime.fromisoformat(updated_at_str.replace('Z', '+00:00'))
            updated_at_naive = updated_at.replace(tzinfo=None)
            days_ago = (datetime.now() - updated_at_naive).days
            years = days_ago // 365
            
            print(f"ID:{article_id} - {years}å¹´å‰ - {article.get('title', 'ç„¡é¡Œ')[:30]}...")
            
            if days_ago >= 365:
                found_old.append({
                    "id": article_id,
                    "title": article.get("title", "ç„¡é¡Œ"),
                    "updated_at": updated_at_str,
                    "days_ago": days_ago,
                    "url": article.get("url"),
                    "scope": article.get("scope", "unknown")
                })
                
        except requests.exceptions.RequestException as e:
            print(f"ID:{article_id} - ã‚¨ãƒ©ãƒ¼: {e}")
            continue
    
    return found_old

def main():
    print("ğŸš€ æ‹¡å¼µå¤ã„è¨˜äº‹æ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
    print("=" * 50)
    
    # 1. åºƒç¯„å›²ãƒšãƒ¼ã‚¸æ¤œç´¢
    old_articles_wide = search_wide_range()
    
    # 2. ç‰¹å®šIDæ¤œç´¢
    old_articles_specific = check_specific_old_articles()
    
    # çµæœã‚’ã¾ã¨ã‚ã‚‹
    all_found = old_articles_wide + old_articles_specific
    
    # é‡è¤‡ã‚’é™¤å»
    unique_articles = {}
    for article in all_found:
        unique_articles[article["id"]] = article
    
    final_old_articles = list(unique_articles.values())
    
    print(f"\nğŸ‰ æœ€çµ‚çµæœ:")
    print(f"   ç™ºè¦‹ã—ãŸ1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹: {len(final_old_articles)} ä»¶")
    
    if final_old_articles:
        # çµæœã‚’ä¿å­˜
        filename = "extended_old_articles.json"
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(final_old_articles, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ’¾ {filename} ã«ä¿å­˜ã—ã¾ã—ãŸ")
        
        # ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        print(f"\nğŸ“‹ ç™ºè¦‹ã—ãŸå¤ã„è¨˜äº‹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰:")
        for i, article in enumerate(sorted(final_old_articles, key=lambda x: x["days_ago"], reverse=True)[:5], 1):
            years = article["days_ago"] // 365
            months = (article["days_ago"] % 365) // 30
            print(f"   {i}. ID:{article['id']} ({years}å¹´{months}ãƒ¶æœˆå‰)")
            print(f"      {article['title'][:50]}...")
        
        print(f"\nğŸ¯ æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—:")
        print(f"   python add_old_article_warning.py --test")
        
    else:
        print(f"\nğŸ’¡ æ‹¡å¼µæ¤œç´¢ã§ã‚‚1å¹´ä»¥ä¸Šå¤ã„è¨˜äº‹ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print("   ã“ã®Docbaseã¯éå¸¸ã«æ´»ç™ºã«æ›´æ–°ã•ã‚Œã¦ã„ã‚‹ã‚ˆã†ã§ã™ï¼")

if __name__ == "__main__":
    main()