#!/usr/bin/env python3
"""
åˆ¥ã®è¨˜äº‹ï¼ˆ707448ï¼‰ã«åŒã˜ãƒ•ãƒ©ã‚°è¨­å®šã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’é©ç”¨
"""

import requests
import json
import os
import re
from dotenv import load_dotenv

load_dotenv()

def get_article(team_name, access_token, post_id):
    """è¨˜äº‹å†…å®¹ã‚’å–å¾—"""
    base_url = "https://api.docbase.io"
    headers = {
        "X-DocBaseToken": access_token,
        "Content-Type": "application/json"
    }
    
    url = f"{base_url}/teams/{team_name}/posts/{post_id}"
    
    try:
        response = requests.get(url, headers=headers)
        response.raise_for_status()
        return response.json()
    except requests.exceptions.RequestException as e:
        print(f"è¨˜äº‹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def analyze_article_structure(body):
    """è¨˜äº‹æ§‹é€ ã‚’åˆ†æ"""
    
    # å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’æ¤œç´¢
    product_pattern = r'## ([ğŸ§Šâ„ï¸ğŸ’¨ğŸ›ï¸ğŸ•ï¸ğŸ“¦ğŸ”‹ğŸ¦ºğŸ§£ğŸ§¤ğŸ“»âš¡]\s*[^#\n\r]+)'
    sections = re.findall(product_pattern, body)
    
    # FAQæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    total_faqs = len(re.findall(r'#### Q:', body))
    
    # ã‚ˆãã‚ã‚‹è³ªå•è¦‹å‡ºã—æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    faq_headers = len(re.findall(r'### ã‚ˆãã‚ã‚‹è³ªå•', body))
    
    # æ—¢å­˜ãƒ•ãƒ©ã‚°æ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
    existing_flags = len(re.findall(r'- \[[ x]\] Webåæ˜ ', body))
    
    return {
        'sections': sections,
        'total_faqs': total_faqs,
        'faq_headers': faq_headers,
        'existing_flags': existing_flags
    }

def add_flags_to_all_faqs(body):
    """å…¨å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®FAQã«ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ """
    
    # å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
    product_pattern = r'(## [ğŸ§Šâ„ï¸ğŸ’¨ğŸ›ï¸ğŸ•ï¸ğŸ“¦ğŸ”‹ğŸ¦ºğŸ§£ğŸ§¤ğŸ“»âš¡]\s*[^#\n\r]+.*?</details>)'
    
    def process_section(match):
        section_content = match.group(1)
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³åã‚’å–å¾—
        section_name_match = re.search(r'## ([ğŸ§Šâ„ï¸ğŸ’¨ğŸ›ï¸ğŸ•ï¸ğŸ“¦ğŸ”‹ğŸ¦ºğŸ§£ğŸ§¤ğŸ“»âš¡]\s*[^#\n\r]+)', section_content)
        section_name = section_name_match.group(1).strip() if section_name_match else "ä¸æ˜"
        
        print(f"ğŸ“¦ å‡¦ç†ä¸­: {section_name}")
        
        # FAQã‚’æŠ½å‡º
        q_pattern = r'#### Q:\s*([^\n\r]+)'
        q_matches = list(re.finditer(q_pattern, section_content))
        
        if not q_matches:
            print(f"   FAQãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return section_content
        
        print(f"   {len(q_matches)}å€‹ã®FAQã‚’ç™ºè¦‹")
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¿æŒï¼ˆã‚ˆãã‚ã‚‹è³ªå•è¦‹å‡ºã—ã‚’é™¤ãï¼‰
        header_parts = []
        
        # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹ã‹ã‚‰detailsã‚¿ã‚°ã¾ã§
        detail_start = section_content.find('<details>')
        if detail_start == -1:
            print(f"   âš ï¸ detailsã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return section_content
            
        # summaryã‚¿ã‚°ã¾ã§
        summary_end = section_content.find('</summary>')
        if summary_end == -1:
            print(f"   âš ï¸ summaryã‚¿ã‚°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return section_content
            
        header = section_content[:summary_end + len('</summary>')]
        footer = "</details>"
        
        # ãƒ•ãƒ©ã‚°ä»˜ãFAQã‚’å†æ§‹ç¯‰
        new_faqs = []
        added_flags = 0
        
        for i, q_match in enumerate(q_matches):
            question = q_match.group(1).strip()
            q_start = q_match.start()
            
            # æ¬¡ã®è³ªå•ã¾ã§ã®ç¯„å›²ã‚’å–å¾—
            if i + 1 < len(q_matches):
                q_end = q_matches[i + 1].start()
            else:
                # ã‚»ã‚¯ã‚·ãƒ§ãƒ³çµ‚äº†ã¾ã§
                q_end = section_content.find('</details>')
                if q_end == -1:
                    q_end = len(section_content)
            
            qa_block = section_content[q_start:q_end]
            
            # å›ç­”ã‚’æŠ½å‡º
            answer_match = re.search(r'\*\*A:\*\*\s*([^#]*?)(?=####|</details>|$)', qa_block, re.DOTALL)
            answer = answer_match.group(1).strip() if answer_match else ""
            
            # ãƒ•ãƒ©ã‚°ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯
            if '- [' in qa_block:
                # æ—¢ã«ãƒ•ãƒ©ã‚°ãŒã‚ã‚‹å ´åˆã¯ãã®ã¾ã¾
                new_faq = qa_block.strip()
                print(f"   â­ï¸ ãƒ•ãƒ©ã‚°æ¸ˆã¿: {question[:40]}...")
            else:
                # ãƒ•ãƒ©ã‚°ãŒãªã„å ´åˆã¯è¿½åŠ ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼šWebåæ˜ å¯¾è±¡ï¼‰
                new_faq = f"""#### Q: {question}
- [ ] Webåæ˜ å¯¾è±¡
**A:** {answer}"""
                added_flags += 1
                print(f"   âœ… ãƒ•ãƒ©ã‚°è¿½åŠ : {question[:40]}...")
            
            new_faqs.append(new_faq)
        
        if added_flags > 0 or q_matches:
            # æ–°ã—ã„ã‚»ã‚¯ã‚·ãƒ§ãƒ³å†…å®¹ã‚’æ§‹ç¯‰
            new_section_content = f"{header}\n\n" + "\n\n".join(new_faqs) + f"\n\n{footer}"
            print(f"   ğŸ“Š {added_flags}å€‹ã®FAQã«ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ã—ã¾ã—ãŸ")
            return new_section_content
        else:
            return section_content
    
    # å„å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã‚’å‡¦ç†
    updated_body = re.sub(product_pattern, process_section, body, flags=re.DOTALL)
    
    return updated_body

def remove_faq_headers(body):
    """ã‚ˆãã‚ã‚‹è³ªå•ã®è¦‹å‡ºã—ã‚’å‰Šé™¤"""
    
    patterns_to_remove = [
        r'### ã‚ˆãã‚ã‚‹è³ªå•\n\n',
        r'### ã‚ˆãã‚ã‚‹è³ªå•\r\n\r\n', 
        r'### ã‚ˆãã‚ã‚‹è³ªå•\n',
        r'### ã‚ˆãã‚ã‚‹è³ªå•\r\n',
        r'### ã‚ˆãã‚ã‚‹è³ªå•',
        r'##\s*ã‚ˆãã‚ã‚‹è³ªå•\n\n',
        r'##\s*ã‚ˆãã‚ã‚‹è³ªå•\r\n\r\n',
        r'##\s*ã‚ˆãã‚ã‚‹è³ªå•\n',
        r'##\s*ã‚ˆãã‚ã‚‹è³ªå•\r\n',
        r'##\s*ã‚ˆãã‚ã‚‹è³ªå•',
    ]
    
    updated_body = body
    removed_count = 0
    
    for pattern in patterns_to_remove:
        matches = re.findall(pattern, updated_body)
        if matches:
            updated_body = re.sub(pattern, '', updated_body)
            removed_count += len(matches)
            print(f"âœ… ãƒ‘ã‚¿ãƒ¼ãƒ³ '{pattern[:20]}...' ã§ {len(matches)}å€‹å‰Šé™¤")
    
    return updated_body, removed_count

def clean_extra_linebreaks(body):
    """ä½™åˆ†ãªæ”¹è¡Œã‚’æ•´ç†"""
    
    # 3ã¤ä»¥ä¸Šé€£ç¶šã™ã‚‹æ”¹è¡Œã‚’2ã¤ã«çµ±ä¸€
    body = re.sub(r'\n{3,}', '\n\n', body)
    body = re.sub(r'\r\n{3,}', '\r\n\r\n', body)
    
    # ã‚»ã‚¯ã‚·ãƒ§ãƒ³é–‹å§‹ç›´å¾Œã®ä½™åˆ†ãªæ”¹è¡Œã‚’å‰Šé™¤
    body = re.sub(r'(<summary>ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹</summary>)\n{3,}', r'\1\n\n', body)
    body = re.sub(r'(<summary>ã‚¯ãƒªãƒƒã‚¯ã—ã¦å±•é–‹</summary>)\r\n{3,}', r'\1\r\n\r\n', body)
    
    return body

def update_article(team_name, access_token, post_id, updated_body):
    """è¨˜äº‹ã‚’æ›´æ–°"""
    base_url = "https://api.docbase.io"
    headers = {
        "X-DocBaseToken": access_token,
        "Content-Type": "application/json"
    }
    
    url = f"{base_url}/teams/{team_name}/posts/{post_id}"
    update_data = {"body": updated_body}
    
    try:
        response = requests.patch(url, headers=headers, json=update_data)
        response.raise_for_status()
        print("âœ… è¨˜äº‹ã®æ›´æ–°ã«æˆåŠŸã—ã¾ã—ãŸï¼")
        return True
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¨˜äº‹ã®æ›´æ–°ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return False

def main():
    TEAM_NAME = "go"
    TARGET_POST_ID = 707448  # å¯¾è±¡è¨˜äº‹ID
    ACCESS_TOKEN = os.getenv("DOCBASE_ACCESS_TOKEN")
    
    if not ACCESS_TOKEN:
        print("ç’°å¢ƒå¤‰æ•° DOCBASE_ACCESS_TOKEN ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return
    
    print("ğŸ”„ è¨˜äº‹707448ã«ãƒ•ãƒ©ã‚°è¨­å®šã¨ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆåŒæœŸ")
    print("=" * 50)
    
    # å¯¾è±¡è¨˜äº‹ã‚’å–å¾—
    print(f"ğŸ“„ è¨˜äº‹ {TARGET_POST_ID} ã‚’å–å¾—ä¸­...")
    article_data = get_article(TEAM_NAME, ACCESS_TOKEN, TARGET_POST_ID)
    
    if not article_data:
        return
    
    original_body = article_data['body']
    
    print(f"ğŸ“‹ è¨˜äº‹æƒ…å ±:")
    print(f"   ã‚¿ã‚¤ãƒˆãƒ«: {article_data.get('title', 'N/A')[:80]}...")
    print(f"   æ–‡å­—æ•°: {len(original_body):,}æ–‡å­—")
    
    # è¨˜äº‹æ§‹é€ ã‚’åˆ†æ
    print(f"\nğŸ” è¨˜äº‹æ§‹é€ ã‚’åˆ†æä¸­...")
    analysis = analyze_article_structure(original_body)
    
    print(f"ğŸ“Š ã€ç¾åœ¨ã®çŠ¶æ³ã€‘")
    print(f"   å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³æ•°: {len(analysis['sections'])}")
    print(f"   ç·FAQæ•°: {analysis['total_faqs']}")
    print(f"   ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€è¦‹å‡ºã—: {analysis['faq_headers']}å€‹")
    print(f"   æ—¢å­˜ãƒ•ãƒ©ã‚°: {analysis['existing_flags']}å€‹")
    
    if analysis['sections']:
        print(f"\nğŸ“¦ å•†å“ã‚»ã‚¯ã‚·ãƒ§ãƒ³ä¸€è¦§:")
        for i, section in enumerate(analysis['sections'][:5], 1):
            print(f"   {i}. {section}")
        if len(analysis['sections']) > 5:
            print(f"   ... ä»– {len(analysis['sections']) - 5} ã‚»ã‚¯ã‚·ãƒ§ãƒ³")
    
    # å‡¦ç†å®Ÿè¡Œ
    updated_body = original_body
    
    # 1. ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ 
    if analysis['total_faqs'] > 0:
        print(f"\nğŸ·ï¸ FAQãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ä¸­...")
        updated_body = add_flags_to_all_faqs(updated_body)
    
    # 2. ã‚ˆãã‚ã‚‹è³ªå•è¦‹å‡ºã—ã‚’å‰Šé™¤
    if analysis['faq_headers'] > 0:
        print(f"\nâœ‚ï¸ ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€è¦‹å‡ºã—ã‚’å‰Šé™¤ä¸­...")
        updated_body, removed_count = remove_faq_headers(updated_body)
        print(f"ğŸ“Š {removed_count}å€‹ã®è¦‹å‡ºã—ã‚’å‰Šé™¤ã—ã¾ã—ãŸ")
    
    # 3. ä½™åˆ†ãªæ”¹è¡Œã‚’æ•´ç†
    print(f"\nğŸ§¹ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ•´ç†ä¸­...")
    updated_body = clean_extra_linebreaks(updated_body)
    
    # æœ€çµ‚ç¢ºèª
    final_analysis = analyze_article_structure(updated_body)
    
    print(f"\nğŸ“Š ã€å‡¦ç†å¾Œã®çŠ¶æ³ã€‘")
    print(f"   ç·FAQæ•°: {final_analysis['total_faqs']}")
    print(f"   ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€è¦‹å‡ºã—: {final_analysis['faq_headers']}å€‹")
    print(f"   ãƒ•ãƒ©ã‚°æ•°: {final_analysis['existing_flags']}å€‹")
    
    # å¤‰æ›´ãŒã‚ã£ãŸå ´åˆã®ã¿æ›´æ–°
    if updated_body != original_body:
        print(f"\nğŸ”„ è¨˜äº‹ã‚’æ›´æ–°ä¸­...")
        success = update_article(TEAM_NAME, ACCESS_TOKEN, TARGET_POST_ID, updated_body)
        
        if success:
            print(f"\nğŸ‰ è¨˜äº‹707448ã®åŒæœŸå®Œäº†ï¼")
            print(f"")
            print(f"ğŸ“± é©ç”¨ã•ã‚ŒãŸå¤‰æ›´:")
            print(f"   â€¢ å…¨FAQã«Webåæ˜ ãƒ•ãƒ©ã‚°ã‚’è¿½åŠ ")
            print(f"   â€¢ ã€Œã‚ˆãã‚ã‚‹è³ªå•ã€è¦‹å‡ºã—ã‚’å‰Šé™¤")
            print(f"   â€¢ ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã‚’æ•´ç†")
            print(f"")
            print(f"ğŸ’¡ ç¢ºèª:")
            print(f"   https://go.docbase.io/posts/{TARGET_POST_ID}")
    else:
        print(f"\nâš ï¸ å¤‰æ›´ã™ã‚‹å†…å®¹ãŒã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
        print(f"   è¨˜äº‹ã¯æ—¢ã«åŒæœŸæ¸ˆã¿ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™")

if __name__ == "__main__":
    main()